
// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'accelerator') {
        try {
            return Math.min( obj, params.max_accelerator as int )
        } catch (all) {
            println "   ### ERROR ###   Max gpu '${params.max_accelerator}' is not valid! Using default value: $obj"
            return obj
        }
    }
}


errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }

def singularityModule = "singularity/3.11.5"

params = [:]
params.max_memory = 144.GB
params.max_cpus = 96
params.max_time = 168.h

process {
    executor = 'slurm'
    queue = 'imielinskilab,a100_long,gpu4_long,cpu_long'
    queueSize = 500
    
//     containerOptions = null
    

    // default SLURM node config
    beforeScript = """
        module load $singularityModule
        module load java
        module load cuda
        module load aws-cli
    """
}

